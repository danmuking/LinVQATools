{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-18T06:17:19.911235300Z",
     "start_time": "2024-01-18T06:17:17.385895900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ly/.conda/envs/torch1.12.1/lib/python3.8/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmengine.logging.logger.MMLogger'> instance named of model has been created, the method `get_instance` should not accept any other arguments\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "os.chdir('/data/ly/code/LinVQATools')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from models.video_mae_vqa import VideoMAEVQAWrapper\n",
    "from data.default_dataset import SingleBranchDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "加载模型和权重"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['model.mean', 'model.std', 'model.mask_token', 'model.pos_embed', 'model.backbone.norm.weight', 'model.backbone.norm.bias', 'model.vqa_head.norm.weight', 'model.vqa_head.norm.bias', 'model.vqa_head.fc_hid.1.weight', 'model.vqa_head.fc_hid.1.bias', 'model.vqa_head.fc_last.0.weight', 'model.vqa_head.fc_last.0.bias', 'model.encoder_to_decoder.weight'], unexpected_keys=['model.backbone.fc_norm.weight', 'model.backbone.fc_norm.bias', 'model.backbone.head.weight', 'model.backbone.head.bias'])\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = VideoMAEVQAWrapper(\n",
    "    model_type='s',\n",
    "    mask_ratio=0.75,\n",
    "    head_dropout=0.1,\n",
    "    drop_path_rate=0.1\n",
    ")\n",
    "weight_path = '/data/ly/code/LinVQATools/work_dir/video_mae_vqa/01171449 vit random_cell_mask_75 mae last 4clip/best_SROCC_epoch_555.pth'\n",
    "weight = torch.load(weight_path,map_location=\"cpu\")\n",
    "info = model.load_state_dict(weight['state_dict'])\n",
    "print(info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T06:17:22.854301Z",
     "start_time": "2024-01-18T06:17:19.911235300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "加载验证集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "num_workers = 6\n",
    "prefix = '4frame'\n",
    "argument = [\n",
    "        dict(\n",
    "            name='FragmentShuffler',\n",
    "            fragment_size=32,\n",
    "            frame_cube=4\n",
    "        ),\n",
    "        dict(\n",
    "            name='PostProcessSampler',\n",
    "            frame_cube=4,\n",
    "            num=4\n",
    "        )\n",
    "]\n",
    "val_video_loader = dict(\n",
    "    name='FragmentLoader',\n",
    "    prefix=prefix,\n",
    "    frame_sampler=None,\n",
    "    spatial_sampler=None,\n",
    "    argument=argument,\n",
    "    phase='test',\n",
    "    use_preprocess=True,\n",
    ")\n",
    "dataset=SingleBranchDataset(\n",
    "    video_loader=val_video_loader,\n",
    "    anno_root='./data/odv_vqa',\n",
    "    anno_reader='ODVVQAReader',\n",
    "    split_file='./data/odv_vqa/tr_te_VQA_ODV.txt',\n",
    "    phase='test',\n",
    "    norm=True,\n",
    "    clip=4\n",
    ")\n",
    "val_dataloader = DataLoader(batch_size=1,\n",
    "                            shuffle=False,\n",
    "                            dataset=dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T06:17:22.855809900Z",
     "start_time": "2024-01-18T06:17:22.853299400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:57<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "gt = []\n",
    "pr = []\n",
    "model = model.cuda().eval()\n",
    "with torch.no_grad():\n",
    "    for item in tqdm(val_dataloader):\n",
    "        gt.append(item['gt_label'])\n",
    "        y = model(inputs=item[\"inputs\"].cuda(), gt_label=item['gt_label'].cuda(),mode='predict')\n",
    "        pr.append(y[0])\n",
    "    # print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T06:18:26.212469800Z",
     "start_time": "2024-01-18T06:17:22.853299400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8916040279325883\n",
      "[0.8833333333333333, 0.9333333333333332, 0.8666666666666667, 0.7333333333333334, 0.8833333333333333, 0.9166666666666666, 0.8833333333333333, 0.8333333333333333, 0.8666666666666667, 0.9500000000000001, 0.9166666666666666, 0.9500000000000001]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import copy\n",
    "\n",
    "all_gt = copy.deepcopy(gt)\n",
    "all_pr = copy.deepcopy(pr)\n",
    "all_gt = torch.tensor(all_gt)\n",
    "all_pr = torch.tensor(all_pr)\n",
    "all_srocc = spearmanr(all_gt, all_pr)[0]\n",
    "print(all_srocc)\n",
    "srocc_list = []\n",
    "for i in range(12):\n",
    "    part_pr = all_pr[i*9:(i+1)*9]\n",
    "    part_gt = all_gt[i*9:(i+1)*9]\n",
    "    srocc = spearmanr(part_gt, part_pr)[0]\n",
    "    srocc_list.append(srocc)\n",
    "print(srocc_list)\n",
    "\n",
    "# 3 0.83, 4 0.9, 12 0.83, 17 0.84, 19 0.61, 21 0.9, 23 0.73, 28 0.78, 30 0.93, 39 0.93, 40 0.91, 58 0.93"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T06:18:26.686936800Z",
     "start_time": "2024-01-18T06:18:26.210397500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [03:08<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "num_workers = 6\n",
    "prefix = '4frame'\n",
    "argument = [\n",
    "        dict(\n",
    "            name='FragmentShuffler',\n",
    "            fragment_size=32,\n",
    "            frame_cube=4\n",
    "        ),\n",
    "        dict(\n",
    "            name='PostProcessSampler',\n",
    "            frame_cube=4,\n",
    "            num=4\n",
    "        )\n",
    "]\n",
    "train_video_loader = dict(\n",
    "    name='FragmentLoader',\n",
    "    prefix=prefix,\n",
    "    frame_sampler=None,\n",
    "    spatial_sampler=None,\n",
    "    argument=argument,\n",
    "    phase='train',\n",
    "    use_preprocess=True,\n",
    ")\n",
    "dataset=SingleBranchDataset(\n",
    "    video_loader=train_video_loader,\n",
    "    anno_root='./data/odv_vqa',\n",
    "    anno_reader='ODVVQAReader',\n",
    "    split_file='./data/odv_vqa/tr_te_VQA_ODV.txt',\n",
    "    phase='train',\n",
    "    norm=True,\n",
    "    clip=4\n",
    ")\n",
    "train_dataloader = DataLoader(batch_size=1,\n",
    "                            shuffle=False,\n",
    "                            dataset=dataset)\n",
    "gt = []\n",
    "pr = []\n",
    "model = model.cuda().eval()\n",
    "with torch.no_grad():\n",
    "    for item in tqdm(train_dataloader):\n",
    "        gt.append(item['gt_label'])\n",
    "        y = model(inputs=item[\"inputs\"].cuda(), gt_label=item['gt_label'].cuda(),mode='predict')\n",
    "        pr.append(y[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T06:21:35.694160600Z",
     "start_time": "2024-01-18T06:18:26.693937300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9671953022343918\n",
      "[0.8666666666666667, 0.9166666666666666, 0.8666666666666667, 0.8499999999999999, 0.9500000000000001, 0.8499999999999999, 0.9666666666666667, 0.8666666666666667, 0.8333333333333333, 0.9, 0.9833333333333333, 0.8666666666666667, 0.7833333333333333, 0.9333333333333332, 0.9333333333333332, 0.8166666666666667, 0.8833333333333333, 0.9833333333333333, 0.7833333333333333, 0.7666666666666667, 0.9500000000000001, 0.9833333333333333, 0.9500000000000001, 0.8166666666666667, 0.8166666666666667, 0.8333333333333333, 0.9500000000000001, 0.9333333333333332, 0.9166666666666666, 0.9, 0.9333333333333332, 0.9333333333333332, 0.8833333333333333, 0.9500000000000001, 0.9833333333333333, 0.8833333333333333, 0.9333333333333332, 0.8666666666666667, 0.8499999999999999, 0.9500000000000001, 1.0, 0.9500000000000001, 0.9333333333333332, 0.9333333333333332, 1.0, 0.9333333333333332, 0.9666666666666667, 0.9500000000000001]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import copy\n",
    "\n",
    "all_gt = copy.deepcopy(gt)\n",
    "all_pr = copy.deepcopy(pr)\n",
    "all_gt = torch.tensor(all_gt)\n",
    "all_pr = torch.tensor(all_pr)\n",
    "all_srocc = spearmanr(all_gt, all_pr)[0]\n",
    "print(all_srocc)\n",
    "srocc_list = []\n",
    "for i in range(48):\n",
    "    part_pr = all_pr[i*9:(i+1)*9]\n",
    "    part_gt = all_gt[i*9:(i+1)*9]\n",
    "    srocc = spearmanr(part_gt, part_pr)[0]\n",
    "    srocc_list.append(srocc)\n",
    "print(srocc_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T06:21:35.801728600Z",
     "start_time": "2024-01-18T06:21:35.701749200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
